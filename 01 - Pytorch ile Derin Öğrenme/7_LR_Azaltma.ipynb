{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162b0333",
   "metadata": {},
   "source": [
    "### Kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff309264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms \n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import (Dataset,DataLoader) \n",
    "from skimage import io\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74b728",
   "metadata": {},
   "source": [
    "### Veriyi Dahil Etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff44574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class veri(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e113187",
   "metadata": {},
   "source": [
    "### Veriyi Hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8fea15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = veri(csv_file = r\"f113.csv\",\n",
    "              root_dir = r\"f1_classification\",\n",
    "              transform = transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  #transforms.ToPILImage(mode=None),\n",
    "                  transforms.Resize(size = (28, 28)),\n",
    "                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2b199e",
   "metadata": {},
   "source": [
    "### Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "306412b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,  test_set = torch.utils.data.random_split(dataset, [200,79]) \n",
    "train_loader = DataLoader(dataset=train_set, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0baf945",
   "metadata": {},
   "source": [
    "### Model Mimarisini Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e45f6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=(5,5))\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=(3,3))\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(2,2)) #22\n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(2,2)) #10\n",
    "        \n",
    "        self.max = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        \n",
    "        self.func = nn.ELU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=32, out_features=50)\n",
    "        #self.fc1 = nn.Linear(in_features=519840, out_features=50)\n",
    "        #self.fc1 = nn.Linear(in_features=32*100*100, out_features=50)\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=100)\n",
    "        self.fc4 = nn.Linear(in_features=100, out_features=4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.func(x)\n",
    "        \n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.func(x)\n",
    "        \n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.func(x)\n",
    "        \n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.func(x)\n",
    "        \n",
    "        #flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #x = x.view(x.size(0), 519840)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.func(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.func(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.func(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d9b4cd",
   "metadata": {},
   "source": [
    "### Modelin Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be68e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 LR: [0.001]\n",
      "Iteration: 100 Loss: 1.5472517013549805 Accuracy: 30.37974739074707% Error: 69.62025451660156%\n",
      "Iteration: 200 Loss: 0.846032440662384 Accuracy: 44.30379867553711% Error: 55.69620132446289%\n",
      "Epoch: 10 LR: [0.00049]\n",
      "Iteration: 300 Loss: 1.0755635499954224 Accuracy: 53.16455841064453% Error: 46.83544158935547%\n",
      "Iteration: 400 Loss: 0.8339922428131104 Accuracy: 48.10126495361328% Error: 51.89873504638672%\n",
      "Epoch: 10 LR: [0.0007]\n",
      "Iteration: 500 Loss: 1.1701064109802246 Accuracy: 63.2911376953125% Error: 36.7088623046875%\n",
      "Iteration: 600 Loss: 0.21413128077983856 Accuracy: 63.2911376953125% Error: 36.7088623046875%\n",
      "Epoch: 10 LR: [0.000343]\n",
      "Iteration: 700 Loss: 1.2134205102920532 Accuracy: 65.82278442382812% Error: 34.177215576171875%\n",
      "Iteration: 800 Loss: 0.06622816622257233 Accuracy: 65.82278442382812% Error: 34.177215576171875%\n",
      "Epoch: 10 LR: [0.00049]\n",
      "Iteration: 900 Loss: 1.040981411933899 Accuracy: 72.15190124511719% Error: 27.848100662231445%\n",
      "Iteration: 1000 Loss: 0.02976696379482746 Accuracy: 68.35443115234375% Error: 31.64556884765625%\n",
      "Epoch: 10 LR: [0.00024009999999999998]\n",
      "Iteration: 1100 Loss: 0.8295117616653442 Accuracy: 68.35443115234375% Error: 31.64556884765625%\n",
      "Iteration: 1200 Loss: 0.019474145025014877 Accuracy: 73.417724609375% Error: 26.582279205322266%\n",
      "Epoch: 10 LR: [0.000343]\n",
      "Iteration: 1300 Loss: 0.5986618399620056 Accuracy: 68.35443115234375% Error: 31.64556884765625%\n",
      "Iteration: 1400 Loss: 0.012479903176426888 Accuracy: 77.2151870727539% Error: 22.78481101989746%\n",
      "Epoch: 10 LR: [0.00016806999999999998]\n",
      "Iteration: 1500 Loss: 0.4129832684993744 Accuracy: 67.08860778808594% Error: 32.91139221191406%\n",
      "Iteration: 1600 Loss: 0.008475997485220432 Accuracy: 77.2151870727539% Error: 22.78481101989746%\n",
      "Epoch: 10 LR: [0.00024009999999999998]\n",
      "Iteration: 1700 Loss: 0.26974669098854065 Accuracy: 65.82278442382812% Error: 34.177215576171875%\n",
      "Iteration: 1800 Loss: 0.006036384031176567 Accuracy: 77.2151870727539% Error: 22.78481101989746%\n",
      "Epoch: 10 LR: [0.00011764899999999998]\n",
      "Iteration: 1900 Loss: 0.12106485664844513 Accuracy: 73.417724609375% Error: 26.582279205322266%\n",
      "Iteration: 2000 Loss: 0.003279666416347027 Accuracy: 77.2151870727539% Error: 22.78481101989746%\n",
      "Süre:  269.286194562912\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Net()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "error = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# step_size kaç epoch'da bir lr'yi düşüreceğini söylüyor 1000 epochluk eğitimde\n",
    "# 100 olarak verilebilir. Gamma ise ne kadar azalacağını çarpan olarak veriyor.\n",
    "lr = StepLR(optimizer, step_size = 2, gamma = 0.7)\n",
    "\n",
    "\n",
    "epoch = 10\n",
    "count = 0\n",
    "loss_list  = []\n",
    "iteration_list = []\n",
    "acc_list = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    lr.step()\n",
    "    print(\"Epoch:\", i, \"LR:\", lr.get_lr())\n",
    "    \n",
    "    for images, label in train_loader:\n",
    "        \n",
    "        tahmin = model(images)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = error(tahmin, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        if count % 100 == 0:\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            correct_hata = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                out = model(images.float())\n",
    "                pred = torch.max(out.data, 1)[1]\n",
    "                total += len(labels)\n",
    "                \n",
    "                correct += (pred == labels).sum()\n",
    "                correct_hata += (pred != labels).sum()\n",
    "                \n",
    "            dogruluk = 100 * correct / float(total)\n",
    "            hata = 100 * correct_hata / float(total)\n",
    "        \n",
    "            loss_list.append(loss.data)\n",
    "            acc_list.append(dogruluk)\n",
    "            iteration_list.append(count)\n",
    "            \n",
    "        if count % 100 == 0:\n",
    "            print(f\"Iteration: {count} Loss: {loss.data} Accuracy: {dogruluk}% Error: {hata}%\")\n",
    "            \n",
    "end = time.time()\n",
    "print(\"Süre: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b109b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
